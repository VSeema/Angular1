{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Marks.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO9ZGFxFam2oTqBKptmF/aH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VSeema/Angular1/blob/master/Marks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yb-XKP6mRmq0",
        "outputId": "10da5077-9a84-43f4-c22e-3e439b7b9af3"
      },
      "source": [
        "!pip install db-sqlite3"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: db-sqlite3 in /usr/local/lib/python3.6/dist-packages (0.0.1)\n",
            "Requirement already satisfied: db in /usr/local/lib/python3.6/dist-packages (from db-sqlite3) (0.1.1)\n",
            "Requirement already satisfied: antiorm in /usr/local/lib/python3.6/dist-packages (from db->db-sqlite3) (1.2.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6eoHfPyRwx3"
      },
      "source": [
        "import pandas as pd\n",
        "import sqlite3"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2-BOTgYRy9V"
      },
      "source": [
        "db=sqlite3.connect(\"test2\")\n",
        "db.execute(\"drop table if exists Marks\")\n",
        "try:\n",
        "  db.execute(\"create table Marks(Roll_No Integer,Name text,Marks Integer)\")\n",
        "except:\n",
        "  print(\"already table existed\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKaGtp8KSEzR"
      },
      "source": [
        "db=sqlite3.connect(\"test2\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykZ8impbSLKT"
      },
      "source": [
        "cmd=\"insert into Marks(Roll_No,Name,Marks) Values('5','suma','50')\";\n",
        "db.execute(cmd);\n",
        "db.commit();"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_zIufTZxTjOP",
        "outputId": "acc8588d-5bbc-4b8b-925c-a9d83ebb0ed0"
      },
      "source": [
        "db=sqlite3.connect(\"test2\")\n",
        "rs=db.execute(\"Select * from Marks\")\n",
        "for row in rs:\n",
        "  print(row)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 'seema', 70)\n",
            "(2, 'siddesh', 80)\n",
            "(3, 'shobha', 90)\n",
            "(4, 'viswa', 100)\n",
            "(5, 'suma', 50)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MX69l935T9t_",
        "outputId": "ece91a31-2c8a-432c-b382-61c1cd4489e3"
      },
      "source": [
        "db=sqlite3.connect(\"test2\")\n",
        "rs=db.execute(\"Select * from Marks where Name='seema'\")\n",
        "for row in rs:\n",
        "  print(row)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 'seema', 70)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "smwegGknUUcS",
        "outputId": "491484f2-181f-464a-9342-dfa3b2f275f4"
      },
      "source": [
        "db=sqlite3.connect(\"test2\")\n",
        "rs=db.execute(\"Select count(*) from Marks\")\n",
        "for row in rs:\n",
        "  print(row)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2JBCqHQUfDh",
        "outputId": "bf0a78c0-55ed-422f-c4c8-86f3e786d6b0"
      },
      "source": [
        "db=sqlite3.connect(\"test2\")\n",
        "rs=db.execute(\"Select Avg(Marks) from Marks\")\n",
        "for row in rs:\n",
        "  print(row)\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(78.0,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYMd_MuRUzBT",
        "outputId": "d38f95dd-f6c8-450a-cf40-6997a37ed1bb"
      },
      "source": [
        "db=sqlite3.connect(\"test2\")\n",
        "rs=db.execute(\"Select SUM(Marks) from Marks\")\n",
        "for row in rs:\n",
        "  print(row)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(390,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "bYaDfsYRU8r0",
        "outputId": "382eaaa3-94ae-4443-ce6b-95e0ebf707b9"
      },
      "source": [
        "db=sqlite3.connect(\"test2\")\n",
        "qry =\"\"\"\n",
        "Select * from Marks\n",
        "\"\"\"\n",
        "mark=pd.read_sql_query(qry,db)\n",
        "mark"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Roll_No</th>\n",
              "      <th>Name</th>\n",
              "      <th>Marks</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>seema</td>\n",
              "      <td>70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>siddesh</td>\n",
              "      <td>80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>shobha</td>\n",
              "      <td>90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>viswa</td>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>suma</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Roll_No     Name  Marks\n",
              "0        1    seema     70\n",
              "1        2  siddesh     80\n",
              "2        3   shobha     90\n",
              "3        4    viswa    100\n",
              "4        5     suma     50"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "if9IlgA2VQij",
        "outputId": "06f3cffe-b3a5-4dc9-bcff-d0c14be2c447"
      },
      "source": [
        "! git clone https://github.com/google-research/tapas.git"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'tapas'...\n",
            "remote: Enumerating objects: 442, done.\u001b[K\n",
            "remote: Total 442 (delta 0), reused 0 (delta 0), pack-reused 442\u001b[K\n",
            "Receiving objects: 100% (442/442), 298.94 KiB | 1000.00 KiB/s, done.\n",
            "Resolving deltas: 100% (276/276), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "o676e11_VVLp",
        "outputId": "7d0c70f2-02c7-416d-dc1d-0ed53e1f3c5d"
      },
      "source": [
        "! pip install ./tapas"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing ./tapas\n",
            "Collecting apache-beam[gcp]==2.20.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4b/0d/0979ad626578a52887f7df60492ac6759089a9da261ac4c88b112b3f6a5a/apache_beam-2.20.0-cp36-cp36m-manylinux1_x86_64.whl (3.5MB)\n",
            "\u001b[K     |████████████████████████████████| 3.5MB 12.2MB/s \n",
            "\u001b[?25hCollecting frozendict==1.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/55/a12ded2c426a4d2bee73f88304c9c08ebbdbadb82569ebdd6a0c007cfd08/frozendict-1.2.tar.gz\n",
            "Collecting pandas~=1.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c0/95/cb9820560a2713384ef49060b0087dfa2591c6db6f240215c2bce1f4211c/pandas-1.0.5-cp36-cp36m-manylinux1_x86_64.whl (10.1MB)\n",
            "\u001b[K     |████████████████████████████████| 10.1MB 35.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn~=0.22.1 in /usr/local/lib/python3.6/dist-packages (from tapas-table-parsing==0.0.1.dev0) (0.22.2.post1)\n",
            "Collecting tensorflow~=2.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/70/e3/663eac537202dee730ad6e61769fc3ebce92a6085dbfd13ca902df5f1477/tensorflow-2.2.1-cp36-cp36m-manylinux2010_x86_64.whl (516.2MB)\n",
            "\u001b[K     |████████████████████████████████| 516.2MB 32kB/s \n",
            "\u001b[?25hCollecting tf-models-official~=2.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/8e/6db83bab2f86475fa69289848379f642746314131527d8a4ced47a6396af/tf_models_official-2.2.2-py2.py3-none-any.whl (711kB)\n",
            "\u001b[K     |████████████████████████████████| 716kB 41.9MB/s \n",
            "\u001b[?25hCollecting kaggle<1.5.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/ab/bb20f9b9e24f9a6250f95a432f8d9a7d745f8d24039d7a5a6eaadb7783ba/kaggle-1.5.6.tar.gz (58kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 8.1MB/s \n",
            "\u001b[?25hCollecting tensorflow-probability==0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ec/61/800c19c1d586b1e06dc9d645f87c158aadf74233d9d03005d2fbef8a2c04/tensorflow_probability-0.10.1-py2.py3-none-any.whl (3.5MB)\n",
            "\u001b[K     |████████████████████████████████| 3.5MB 41.1MB/s \n",
            "\u001b[?25hCollecting tf_slim~=1.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/97/b0f4a64df018ca018cc035d44f2ef08f91e2e8aa67271f6f19633a015ff7/tf_slim-1.1.0-py2.py3-none-any.whl (352kB)\n",
            "\u001b[K     |████████████████████████████████| 358kB 49.8MB/s \n",
            "\u001b[?25hCollecting nltk~=3.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/75/ce35194d8e3022203cca0d2f896dbb88689f9b3fce8e9f9cff942913519d/nltk-3.5.zip (1.4MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4MB 51.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses~=0.7 in /usr/local/lib/python3.6/dist-packages (from tapas-table-parsing==0.0.1.dev0) (0.8)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.8.0 in /usr/local/lib/python3.6/dist-packages (from apache-beam[gcp]==2.20.0->tapas-table-parsing==0.0.1.dev0) (2.8.1)\n",
            "Requirement already satisfied: typing-extensions<3.8.0,>=3.7.0 in /usr/local/lib/python3.6/dist-packages (from apache-beam[gcp]==2.20.0->tapas-table-parsing==0.0.1.dev0) (3.7.4.3)\n",
            "Requirement already satisfied: grpcio<2,>=1.12.1 in /usr/local/lib/python3.6/dist-packages (from apache-beam[gcp]==2.20.0->tapas-table-parsing==0.0.1.dev0) (1.33.2)\n",
            "Collecting mock<3.0.0,>=1.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e6/35/f187bdf23be87092bd0f1200d43d23076cee4d0dec109f195173fd3ebc79/mock-2.0.0-py2.py3-none-any.whl (56kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 8.1MB/s \n",
            "\u001b[?25hCollecting avro-python3!=1.9.2,<1.10.0,>=1.8.1; python_version >= \"3.0\"\n",
            "  Downloading https://files.pythonhosted.org/packages/5a/80/acd1455bea0a9fcdc60a748a97dcbb3ff624726fb90987a0fc1c19e7a5a5/avro-python3-1.9.2.1.tar.gz\n",
            "Requirement already satisfied: protobuf<4,>=3.5.0.post1 in /usr/local/lib/python3.6/dist-packages (from apache-beam[gcp]==2.20.0->tapas-table-parsing==0.0.1.dev0) (3.12.4)\n",
            "Requirement already satisfied: pymongo<4.0.0,>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from apache-beam[gcp]==2.20.0->tapas-table-parsing==0.0.1.dev0) (3.11.1)\n",
            "Requirement already satisfied: numpy<2,>=1.14.3 in /usr/local/lib/python3.6/dist-packages (from apache-beam[gcp]==2.20.0->tapas-table-parsing==0.0.1.dev0) (1.18.5)\n",
            "Collecting pyarrow<0.17.0,>=0.15.1; python_version >= \"3.0\" or platform_system != \"Windows\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/00/d2/695bab1e1e7a4554b6dbd287d55cca096214bd441037058a432afd724bb1/pyarrow-0.16.0-cp36-cp36m-manylinux2014_x86_64.whl (63.1MB)\n",
            "\u001b[K     |████████████████████████████████| 63.2MB 74kB/s \n",
            "\u001b[?25hCollecting httplib2<=0.12.0,>=0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ce/ed/803905d670b52fa0edfdd135337e545b4496c2ab3a222f1449b7256eb99f/httplib2-0.12.0.tar.gz (218kB)\n",
            "\u001b[K     |████████████████████████████████| 225kB 51.1MB/s \n",
            "\u001b[?25hCollecting dill<0.3.2,>=0.3.1.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c7/11/345f3173809cea7f1a193bfbf02403fff250a3360e0e118a1630985e547d/dill-0.3.1.1.tar.gz (151kB)\n",
            "\u001b[K     |████████████████████████████████| 153kB 47.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: future<1.0.0,>=0.16.0 in /usr/local/lib/python3.6/dist-packages (from apache-beam[gcp]==2.20.0->tapas-table-parsing==0.0.1.dev0) (0.16.0)\n",
            "Collecting hdfs<3.0.0,>=2.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/82/39/2c0879b1bcfd1f6ad078eb210d09dbce21072386a3997074ee91e60ddc5a/hdfs-2.5.8.tar.gz (41kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 7.3MB/s \n",
            "\u001b[?25hCollecting oauth2client<4,>=2.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c0/7b/bc893e35d6ca46a72faa4b9eaac25c687ce60e1fbe978993fe2de1b0ff0d/oauth2client-3.0.0.tar.gz (77kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 9.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytz>=2018.3 in /usr/local/lib/python3.6/dist-packages (from apache-beam[gcp]==2.20.0->tapas-table-parsing==0.0.1.dev0) (2018.9)\n",
            "Requirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from apache-beam[gcp]==2.20.0->tapas-table-parsing==0.0.1.dev0) (1.3.0)\n",
            "Requirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.6/dist-packages (from apache-beam[gcp]==2.20.0->tapas-table-parsing==0.0.1.dev0) (1.7)\n",
            "Collecting fastavro<0.22,>=0.21.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e1/28/0206330c0002b1e28e21473117d0dc813defbd5891562d27af5c68c93899/fastavro-0.21.24-cp36-cp36m-manylinux1_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 42.4MB/s \n",
            "\u001b[?25hCollecting google-cloud-videointelligence<1.14.0,>=1.8.0; extra == \"gcp\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/bd/9945e21aace32bc45a17b65944b5cd20efb7370985d8984425831a47ca22/google_cloud_videointelligence-1.13.0-py2.py3-none-any.whl (177kB)\n",
            "\u001b[K     |████████████████████████████████| 184kB 52.5MB/s \n",
            "\u001b[?25hCollecting google-cloud-dlp<=0.13.0,>=0.12.0; extra == \"gcp\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/24/65/c74f730d5c08affdb056250e601f77c54c0f7c13dfd1c865e02f98b4e7b4/google_cloud_dlp-0.13.0-py2.py3-none-any.whl (151kB)\n",
            "\u001b[K     |████████████████████████████████| 153kB 50.8MB/s \n",
            "\u001b[?25hCollecting google-cloud-language<2,>=1.3.0; extra == \"gcp\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ba/b8/965a97ba60287910d342623da1da615254bded3e0965728cf7fc6339b7c8/google_cloud_language-1.3.0-py2.py3-none-any.whl (83kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 11.9MB/s \n",
            "\u001b[?25hCollecting google-cloud-pubsub<1.1.0,>=0.39.0; extra == \"gcp\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d3/91/07a82945a7396ea34debafd476724bb5fc267c292790fdf2138c693f95c5/google_cloud_pubsub-1.0.2-py2.py3-none-any.whl (118kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 52.3MB/s \n",
            "\u001b[?25hCollecting cachetools<4,>=3.1.0; extra == \"gcp\"\n",
            "  Downloading https://files.pythonhosted.org/packages/2f/a6/30b0a0bef12283e83e58c1d6e7b5aabc7acfc4110df81a4471655d33e704/cachetools-3.1.1-py2.py3-none-any.whl\n",
            "Collecting google-cloud-bigtable<1.1.0,>=0.31.1; extra == \"gcp\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/af/0ef7d097a1d5ad0c843867600e86de915e8ab8864740f49a4636cfb51af6/google_cloud_bigtable-1.0.0-py2.py3-none-any.whl (232kB)\n",
            "\u001b[K     |████████████████████████████████| 235kB 55.1MB/s \n",
            "\u001b[?25hCollecting google-cloud-spanner<1.14.0,>=1.13.0; extra == \"gcp\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/39/c5e470bf59ce15716490bea1945e2c03b4f08f2153285f19dc6f9337b9e9/google_cloud_spanner-1.13.0-py2.py3-none-any.whl (212kB)\n",
            "\u001b[K     |████████████████████████████████| 215kB 50.4MB/s \n",
            "\u001b[?25hCollecting google-cloud-vision<0.43.0,>=0.38.0; extra == \"gcp\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/eb/23/6d5a728333ce568fb484d0d7edd0b7c04b16cf6325af31d957eb51ed077d/google_cloud_vision-0.42.0-py2.py3-none-any.whl (435kB)\n",
            "\u001b[K     |████████████████████████████████| 440kB 49.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-cloud-core<2,>=0.28.1; extra == \"gcp\" in /usr/local/lib/python3.6/dist-packages (from apache-beam[gcp]==2.20.0->tapas-table-parsing==0.0.1.dev0) (1.0.3)\n",
            "Collecting google-cloud-datastore<1.8.0,>=1.7.1; extra == \"gcp\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/aa/29cbcf8cf7d08ce2d55b9dce858f7c632b434cb6451bed17cb4275804217/google_cloud_datastore-1.7.4-py2.py3-none-any.whl (82kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 10.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-cloud-bigquery<=1.24.0,>=1.6.0; extra == \"gcp\" in /usr/local/lib/python3.6/dist-packages (from apache-beam[gcp]==2.20.0->tapas-table-parsing==0.0.1.dev0) (1.21.0)\n",
            "Collecting google-apitools<0.5.29,>=0.5.28; extra == \"gcp\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7f/32/df3e36fd705a00092f1ffa9f41ce1df8dcb594ae313d239b87861a41fc2e/google-apitools-0.5.28.tar.gz (172kB)\n",
            "\u001b[K     |████████████████████████████████| 174kB 45.8MB/s \n",
            "\u001b[?25hCollecting grpcio-gcp<1,>=0.2.2; extra == \"gcp\"\n",
            "  Downloading https://files.pythonhosted.org/packages/ba/83/1f1095815be0de19102df41e250ebbd7dae97d7d14e22c18da07ed5ed9d4/grpcio_gcp-0.2.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn~=0.22.1->tapas-table-parsing==0.0.1.dev0) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn~=0.22.1->tapas-table-parsing==0.0.1.dev0) (0.17.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.2.0->tapas-table-parsing==0.0.1.dev0) (0.35.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.2.0->tapas-table-parsing==0.0.1.dev0) (3.3.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.2.0->tapas-table-parsing==0.0.1.dev0) (0.3.3)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.2.0->tapas-table-parsing==0.0.1.dev0) (0.10.0)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.2.0->tapas-table-parsing==0.0.1.dev0) (2.10.0)\n",
            "Collecting tensorflow-estimator<2.3.0,>=2.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a4/f5/926ae53d6a226ec0fda5208e0e581cffed895ccc89e36ba76a8e60895b78/tensorflow_estimator-2.2.0-py2.py3-none-any.whl (454kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 29.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.2.0->tapas-table-parsing==0.0.1.dev0) (1.15.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.2.0->tapas-table-parsing==0.0.1.dev0) (0.2.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.2.0->tapas-table-parsing==0.0.1.dev0) (1.12.1)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.2.0->tapas-table-parsing==0.0.1.dev0) (1.6.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.2.0->tapas-table-parsing==0.0.1.dev0) (1.1.0)\n",
            "Collecting tensorboard<2.3.0,>=2.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1d/74/0a6fcb206dcc72a6da9a62dd81784bfdbff5fedb099982861dc2219014fb/tensorboard-2.2.2-py3-none-any.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 37.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.2.0->tapas-table-parsing==0.0.1.dev0) (1.1.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from tf-models-official~=2.2.0->tapas-table-parsing==0.0.1.dev0) (3.13)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from tf-models-official~=2.2.0->tapas-table-parsing==0.0.1.dev0) (7.0.0)\n",
            "Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tf-models-official~=2.2.0->tapas-table-parsing==0.0.1.dev0) (0.10.0)\n",
            "Collecting tensorflow-model-optimization>=0.2.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/55/38/4fd48ea1bfcb0b6e36d949025200426fe9c3a8bfae029f0973d85518fa5a/tensorflow_model_optimization-0.5.0-py2.py3-none-any.whl (172kB)\n",
            "\u001b[K     |████████████████████████████████| 174kB 52.1MB/s \n",
            "\u001b[?25hCollecting typing==3.7.4.1\n",
            "  Downloading https://files.pythonhosted.org/packages/fe/2e/b480ee1b75e6d17d2993738670e75c1feeb9ff7f64452153cf018051cc92/typing-3.7.4.1-py3-none-any.whl\n",
            "Collecting opencv-python-headless\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/08/e9/57d869561389884136be65a2d1bc038fe50171e2ba348fda269a4aab8032/opencv_python_headless-4.4.0.46-cp36-cp36m-manylinux2014_x86_64.whl (36.7MB)\n",
            "\u001b[K     |████████████████████████████████| 36.7MB 130kB/s \n",
            "\u001b[?25hCollecting mlperf-compliance==0.0.10\n",
            "  Downloading https://files.pythonhosted.org/packages/f4/08/f2febd8cbd5c9371f7dab311e90400d83238447ba7609b3bf0145b4cb2a2/mlperf_compliance-0.0.10-py3-none-any.whl\n",
            "Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.6/dist-packages (from tf-models-official~=2.2.0->tapas-table-parsing==0.0.1.dev0) (5.4.8)\n",
            "Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.6/dist-packages (from tf-models-official~=2.2.0->tapas-table-parsing==0.0.1.dev0) (0.8.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from tf-models-official~=2.2.0->tapas-table-parsing==0.0.1.dev0) (3.2.2)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.6/dist-packages (from tf-models-official~=2.2.0->tapas-table-parsing==0.0.1.dev0) (0.3.0)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.6/dist-packages (from tf-models-official~=2.2.0->tapas-table-parsing==0.0.1.dev0) (4.0.1)\n",
            "Collecting py-cpuinfo>=3.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f6/f5/8e6e85ce2e9f6e05040cf0d4e26f43a4718bcc4bce988b433276d4b1a5c1/py-cpuinfo-7.0.0.tar.gz (95kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 11.1MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/2d/6d4ca4bef9a67070fa1cac508606328329152b1df10bdf31fb6e4e727894/sentencepiece-0.1.94-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 38.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: Cython in /usr/local/lib/python3.6/dist-packages (from tf-models-official~=2.2.0->tapas-table-parsing==0.0.1.dev0) (0.29.21)\n",
            "Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.6/dist-packages (from tf-models-official~=2.2.0->tapas-table-parsing==0.0.1.dev0) (1.7.12)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from kaggle<1.5.8->tapas-table-parsing==0.0.1.dev0) (1.24.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle<1.5.8->tapas-table-parsing==0.0.1.dev0) (2020.11.8)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle<1.5.8->tapas-table-parsing==0.0.1.dev0) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle<1.5.8->tapas-table-parsing==0.0.1.dev0) (4.41.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle<1.5.8->tapas-table-parsing==0.0.1.dev0) (4.0.1)\n",
            "Requirement already satisfied: cloudpickle==1.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability==0.10.1->tapas-table-parsing==0.0.1.dev0) (1.3.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability==0.10.1->tapas-table-parsing==0.0.1.dev0) (4.4.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from nltk~=3.5->tapas-table-parsing==0.0.1.dev0) (7.1.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from nltk~=3.5->tapas-table-parsing==0.0.1.dev0) (2019.12.20)\n",
            "Collecting pbr>=0.11\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fb/48/69046506f6ac61c1eaa9a0d42d22d54673b69e176d30ca98e3f61513e980/pbr-5.5.1-py2.py3-none-any.whl (106kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 54.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf<4,>=3.5.0.post1->apache-beam[gcp]==2.20.0->tapas-table-parsing==0.0.1.dev0) (50.3.2)\n",
            "Requirement already satisfied: docopt in /usr/local/lib/python3.6/dist-packages (from hdfs<3.0.0,>=2.1.0->apache-beam[gcp]==2.20.0->tapas-table-parsing==0.0.1.dev0) (0.6.2)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client<4,>=2.0.1->apache-beam[gcp]==2.20.0->tapas-table-parsing==0.0.1.dev0) (0.4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client<4,>=2.0.1->apache-beam[gcp]==2.20.0->tapas-table-parsing==0.0.1.dev0) (0.2.8)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client<4,>=2.0.1->apache-beam[gcp]==2.20.0->tapas-table-parsing==0.0.1.dev0) (4.6)\n",
            "Requirement already satisfied: pyparsing>=2.1.4 in /usr/local/lib/python3.6/dist-packages (from pydot<2,>=1.2.0->apache-beam[gcp]==2.20.0->tapas-table-parsing==0.0.1.dev0) (2.4.7)\n",
            "Requirement already satisfied: google-api-core[grpc]<2.0.0dev,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from google-cloud-videointelligence<1.14.0,>=1.8.0; extra == \"gcp\"->apache-beam[gcp]==2.20.0->tapas-table-parsing==0.0.1.dev0) (1.16.0)\n",
            "Collecting grpc-google-iam-v1<0.13dev,>=0.12.3\n",
            "  Downloading https://files.pythonhosted.org/packages/65/19/2060c8faa325fddc09aa67af98ffcb6813f39a0ad805679fa64815362b3a/grpc-google-iam-v1-0.12.3.tar.gz\n",
            "Requirement already satisfied: google-resumable-media!=0.4.0,<0.5.0dev,>=0.3.1 in /usr/local/lib/python3.6/dist-packages (from google-cloud-bigquery<=1.24.0,>=1.6.0; extra == \"gcp\"->apache-beam[gcp]==2.20.0->tapas-table-parsing==0.0.1.dev0) (0.4.1)\n",
            "Collecting fasteners>=0.14\n",
            "  Downloading https://files.pythonhosted.org/packages/18/bd/55eb2d6397b9c0e263af9d091ebdb756b15756029b3cededf6461481bc63/fasteners-0.15-py2.py3-none-any.whl\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow~=2.2.0->tapas-table-parsing==0.0.1.dev0) (3.3.3)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow~=2.2.0->tapas-table-parsing==0.0.1.dev0) (1.17.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow~=2.2.0->tapas-table-parsing==0.0.1.dev0) (1.7.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow~=2.2.0->tapas-table-parsing==0.0.1.dev0) (0.4.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow~=2.2.0->tapas-table-parsing==0.0.1.dev0) (1.0.1)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-model-optimization>=0.2.1->tf-models-official~=2.2.0->tapas-table-parsing==0.0.1.dev0) (0.1.5)\n",
            "Requirement already satisfied: typeguard in /usr/local/lib/python3.6/dist-packages (from tensorflow-addons->tf-models-official~=2.2.0->tapas-table-parsing==0.0.1.dev0) (2.7.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->tf-models-official~=2.2.0->tapas-table-parsing==0.0.1.dev0) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->tf-models-official~=2.2.0->tapas-table-parsing==0.0.1.dev0) (1.3.1)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->tf-models-official~=2.2.0->tapas-table-parsing==0.0.1.dev0) (0.25.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->tf-models-official~=2.2.0->tapas-table-parsing==0.0.1.dev0) (2.3)\n",
            "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->tf-models-official~=2.2.0->tapas-table-parsing==0.0.1.dev0) (20.3.0)\n",
            "Requirement already satisfied: importlib-resources; python_version < \"3.9\" in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->tf-models-official~=2.2.0->tapas-table-parsing==0.0.1.dev0) (3.3.0)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.6.7->tf-models-official~=2.2.0->tapas-table-parsing==0.0.1.dev0) (0.0.4)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.6.7->tf-models-official~=2.2.0->tapas-table-parsing==0.0.1.dev0) (3.0.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle<1.5.8->tapas-table-parsing==0.0.1.dev0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle<1.5.8->tapas-table-parsing==0.0.1.dev0) (2.10)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle<1.5.8->tapas-table-parsing==0.0.1.dev0) (1.3)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-videointelligence<1.14.0,>=1.8.0; extra == \"gcp\"->apache-beam[gcp]==2.20.0->tapas-table-parsing==0.0.1.dev0) (1.52.0)\n",
            "Collecting monotonic>=0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/ac/aa/063eca6a416f397bd99552c534c6d11d57f58f2e94c14780f3bbf818c4cf/monotonic-1.5-py2.py3-none-any.whl\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow~=2.2.0->tapas-table-parsing==0.0.1.dev0) (2.0.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow~=2.2.0->tapas-table-parsing==0.0.1.dev0) (1.3.0)\n",
            "Requirement already satisfied: zipp>=0.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-resources; python_version < \"3.9\"->tensorflow-datasets->tf-models-official~=2.2.0->tapas-table-parsing==0.0.1.dev0) (3.4.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow~=2.2.0->tapas-table-parsing==0.0.1.dev0) (3.1.0)\n",
            "Building wheels for collected packages: tapas-table-parsing, frozendict, kaggle, nltk, avro-python3, httplib2, dill, hdfs, oauth2client, google-apitools, py-cpuinfo, grpc-google-iam-v1\n",
            "  Building wheel for tapas-table-parsing (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tapas-table-parsing: filename=tapas_table_parsing-0.0.1.dev0-cp36-none-any.whl size=224991 sha256=754c56d65359fb5575018484f6e22c3c9fa12041cbb9d128e5d6e75bb88c5076\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-0ac4fwun/wheels/2f/0b/d5/7e7fd15d1eb9839bd9768eaa6af2e0446329927b0f0c351387\n",
            "  Building wheel for frozendict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for frozendict: filename=frozendict-1.2-cp36-none-any.whl size=3149 sha256=527a5f4ddb9bc18462a1100fb585bb8d1a3403760a4743272c013ae56807fdc0\n",
            "  Stored in directory: /root/.cache/pip/wheels/6c/6c/e9/534386165bd12cf1885582c75eb6d0ffcb321b65c23fe0f834\n",
            "  Building wheel for kaggle (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kaggle: filename=kaggle-1.5.6-cp36-none-any.whl size=72859 sha256=5a32a04ccfcfbd4b7fba526be2efb5a7f9d09e30e5f8c7c3454b1dff4d2a02e5\n",
            "  Stored in directory: /root/.cache/pip/wheels/57/4e/e8/bb28d035162fb8f17f8ca5d42c3230e284c6aa565b42b72674\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nltk: filename=nltk-3.5-cp36-none-any.whl size=1434672 sha256=5598c8e54186d6489285914d62a9ef3027172bfab54096b85592311f285e3352\n",
            "  Stored in directory: /root/.cache/pip/wheels/ae/8c/3f/b1fe0ba04555b08b57ab52ab7f86023639a526d8bc8d384306\n",
            "  Building wheel for avro-python3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for avro-python3: filename=avro_python3-1.9.2.1-cp36-none-any.whl size=43516 sha256=86522d0022b9d77ca9ae8771a9e80afd3a3fbb40226b83447e0fd5be782110c0\n",
            "  Stored in directory: /root/.cache/pip/wheels/5a/d3/be/86620c9dd3fca68986c33b9c616510289fc0abb81ec9aa70bd\n",
            "  Building wheel for httplib2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for httplib2: filename=httplib2-0.12.0-cp36-none-any.whl size=93466 sha256=7e8c4a03c1d3a7028d9641115476e1b9a01b27e3618a16a6ff28cae5658fb0ae\n",
            "  Stored in directory: /root/.cache/pip/wheels/6d/41/4b/2b369d6e2b7eaebcdd423516d3fb659c7658c16a2be8fd04ec\n",
            "  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dill: filename=dill-0.3.1.1-cp36-none-any.whl size=78532 sha256=04599def7a4c64ddb0ecbedf65d7239b98e536666eb9567259d380660956a13b\n",
            "  Stored in directory: /root/.cache/pip/wheels/59/b1/91/f02e76c732915c4015ab4010f3015469866c1eb9b14058d8e7\n",
            "  Building wheel for hdfs (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hdfs: filename=hdfs-2.5.8-cp36-none-any.whl size=33213 sha256=4b9da3f56fd810fa0b2fd421fd1ecfd1ef8b8408e65f3e1e91fa5ebc96615a6b\n",
            "  Stored in directory: /root/.cache/pip/wheels/fe/a7/05/23e3699975fc20f8a30e00ac1e515ab8c61168e982abe4ce70\n",
            "  Building wheel for oauth2client (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for oauth2client: filename=oauth2client-3.0.0-cp36-none-any.whl size=106382 sha256=272b9ca70e8933da149dd1b9990e74f2e72a6d89ef23a5098080cd5cb945fae6\n",
            "  Stored in directory: /root/.cache/pip/wheels/48/f7/87/b932f09c6335dbcf45d916937105a372ab14f353a9ca431d7d\n",
            "  Building wheel for google-apitools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for google-apitools: filename=google_apitools-0.5.28-cp36-none-any.whl size=130112 sha256=bbee3a67b8b94daa220881de71a57096b5ab5c9f5f82b4d3b91ff786fbfd77f3\n",
            "  Stored in directory: /root/.cache/pip/wheels/d6/c2/92/837e8a4d649a209dff85b38d7fbb576b4b480738be70865f29\n",
            "  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py-cpuinfo: filename=py_cpuinfo-7.0.0-cp36-none-any.whl size=20071 sha256=128c1476ca74e61445fbfb49911d9850c35071f155a1fea4deb318e1adc4a915\n",
            "  Stored in directory: /root/.cache/pip/wheels/f1/93/7b/127daf0c3a5a49feb2fecd468d508067c733fba5192f726ad1\n",
            "  Building wheel for grpc-google-iam-v1 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for grpc-google-iam-v1: filename=grpc_google_iam_v1-0.12.3-cp36-none-any.whl size=18500 sha256=5efc356393b86d81a3abb0730d2593cb003a8f5e1bafa1353f66bcedb1015728\n",
            "  Stored in directory: /root/.cache/pip/wheels/de/3a/83/77a1e18e1a8757186df834b86ce6800120ac9c79cd8ca4091b\n",
            "Successfully built tapas-table-parsing frozendict kaggle nltk avro-python3 httplib2 dill hdfs oauth2client google-apitools py-cpuinfo grpc-google-iam-v1\n",
            "\u001b[31mERROR: pydrive 1.3.1 has requirement oauth2client>=4.0.0, but you'll have oauth2client 3.0.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: multiprocess 0.70.11.1 has requirement dill>=0.3.3, but you'll have dill 0.3.1.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement pandas~=1.1.0; python_version >= \"3.0\", but you'll have pandas 1.0.5 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-api-python-client 1.7.12 has requirement httplib2<1dev,>=0.17.0, but you'll have httplib2 0.12.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: pbr, mock, avro-python3, pyarrow, httplib2, dill, hdfs, oauth2client, fastavro, google-cloud-videointelligence, google-cloud-dlp, google-cloud-language, grpc-google-iam-v1, google-cloud-pubsub, cachetools, google-cloud-bigtable, google-cloud-spanner, google-cloud-vision, google-cloud-datastore, monotonic, fasteners, google-apitools, grpcio-gcp, apache-beam, frozendict, pandas, tensorflow-estimator, tensorboard, tensorflow, kaggle, tensorflow-model-optimization, typing, opencv-python-headless, mlperf-compliance, py-cpuinfo, sentencepiece, tf-models-official, tensorflow-probability, tf-slim, nltk, tapas-table-parsing\n",
            "  Found existing installation: pyarrow 0.14.1\n",
            "    Uninstalling pyarrow-0.14.1:\n",
            "      Successfully uninstalled pyarrow-0.14.1\n",
            "  Found existing installation: httplib2 0.17.4\n",
            "    Uninstalling httplib2-0.17.4:\n",
            "      Successfully uninstalled httplib2-0.17.4\n",
            "  Found existing installation: dill 0.3.3\n",
            "    Uninstalling dill-0.3.3:\n",
            "      Successfully uninstalled dill-0.3.3\n",
            "  Found existing installation: oauth2client 4.1.3\n",
            "    Uninstalling oauth2client-4.1.3:\n",
            "      Successfully uninstalled oauth2client-4.1.3\n",
            "  Found existing installation: google-cloud-language 1.2.0\n",
            "    Uninstalling google-cloud-language-1.2.0:\n",
            "      Successfully uninstalled google-cloud-language-1.2.0\n",
            "  Found existing installation: cachetools 4.1.1\n",
            "    Uninstalling cachetools-4.1.1:\n",
            "      Successfully uninstalled cachetools-4.1.1\n",
            "  Found existing installation: google-cloud-datastore 1.8.0\n",
            "    Uninstalling google-cloud-datastore-1.8.0:\n",
            "      Successfully uninstalled google-cloud-datastore-1.8.0\n",
            "  Found existing installation: pandas 1.1.4\n",
            "    Uninstalling pandas-1.1.4:\n",
            "      Successfully uninstalled pandas-1.1.4\n",
            "  Found existing installation: tensorflow-estimator 2.3.0\n",
            "    Uninstalling tensorflow-estimator-2.3.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.3.0\n",
            "  Found existing installation: tensorboard 2.3.0\n",
            "    Uninstalling tensorboard-2.3.0:\n",
            "      Successfully uninstalled tensorboard-2.3.0\n",
            "  Found existing installation: tensorflow 2.3.0\n",
            "    Uninstalling tensorflow-2.3.0:\n",
            "      Successfully uninstalled tensorflow-2.3.0\n",
            "  Found existing installation: kaggle 1.5.9\n",
            "    Uninstalling kaggle-1.5.9:\n",
            "      Successfully uninstalled kaggle-1.5.9\n",
            "  Found existing installation: tensorflow-probability 0.11.0\n",
            "    Uninstalling tensorflow-probability-0.11.0:\n",
            "      Successfully uninstalled tensorflow-probability-0.11.0\n",
            "  Found existing installation: nltk 3.2.5\n",
            "    Uninstalling nltk-3.2.5:\n",
            "      Successfully uninstalled nltk-3.2.5\n",
            "Successfully installed apache-beam-2.20.0 avro-python3-1.9.2.1 cachetools-3.1.1 dill-0.3.1.1 fastavro-0.21.24 fasteners-0.15 frozendict-1.2 google-apitools-0.5.28 google-cloud-bigtable-1.0.0 google-cloud-datastore-1.7.4 google-cloud-dlp-0.13.0 google-cloud-language-1.3.0 google-cloud-pubsub-1.0.2 google-cloud-spanner-1.13.0 google-cloud-videointelligence-1.13.0 google-cloud-vision-0.42.0 grpc-google-iam-v1-0.12.3 grpcio-gcp-0.2.2 hdfs-2.5.8 httplib2-0.12.0 kaggle-1.5.6 mlperf-compliance-0.0.10 mock-2.0.0 monotonic-1.5 nltk-3.5 oauth2client-3.0.0 opencv-python-headless-4.4.0.46 pandas-1.0.5 pbr-5.5.1 py-cpuinfo-7.0.0 pyarrow-0.16.0 sentencepiece-0.1.94 tapas-table-parsing-0.0.1.dev0 tensorboard-2.2.2 tensorflow-2.2.1 tensorflow-estimator-2.2.0 tensorflow-model-optimization-0.5.0 tensorflow-probability-0.10.1 tf-models-official-2.2.2 tf-slim-1.1.0 typing-3.7.4.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google",
                  "pandas",
                  "typing"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJhUzETbVYG5",
        "outputId": "f7135e54-5428-4e07-fcbe-cbad994a3fa4"
      },
      "source": [
        "! gsutil cp gs://tapas_models/2020_04_21/tapas_sqa_base.zip . && unzip tapas_sqa_base.zip"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying gs://tapas_models/2020_04_21/tapas_sqa_base.zip...\n",
            "/ [1 files][  1.0 GiB/  1.0 GiB]   22.1 MiB/s                                   \n",
            "Operation completed over 1 objects/1.0 GiB.                                      \n",
            "Archive:  tapas_sqa_base.zip\n",
            "   creating: tapas_sqa_base/\n",
            "  inflating: tapas_sqa_base/model.ckpt.data-00000-of-00001  \n",
            "  inflating: tapas_sqa_base/model.ckpt.index  \n",
            "  inflating: tapas_sqa_base/README.txt  \n",
            "  inflating: tapas_sqa_base/vocab.txt  \n",
            "  inflating: tapas_sqa_base/bert_config.json  \n",
            "  inflating: tapas_sqa_base/model.ckpt.meta  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6AWRdi76WJ-u"
      },
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "import os \n",
        "import shutil\n",
        "import csv\n",
        "import pandas as pd\n",
        "import IPython\n",
        "\n",
        "tf.get_logger().setLevel('ERROR')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKdTLLNXWcpm"
      },
      "source": [
        "from tapas.utils import tf_example_utils\n",
        "from tapas.protos import interaction_pb2\n",
        "from tapas.utils import number_annotation_utils\n",
        "from tapas.scripts import prediction_utils"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rnc2FtAPWeqG"
      },
      "source": [
        "os.makedirs('results/sqa/tf_examples', exist_ok=True)\n",
        "os.makedirs('results/sqa/model', exist_ok=True)\n",
        "with open('results/sqa/model/checkpoint', 'w') as f:\n",
        "  f.write('model_checkpoint_path: \"model.ckpt-0\"')\n",
        "for suffix in ['.data-00000-of-00001', '.index', '.meta']:\n",
        "  shutil.copyfile(f'tapas_sqa_base/model.ckpt{suffix}', f'results/sqa/model/model.ckpt-0{suffix}')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOOBZO0SWg2V"
      },
      "source": [
        "mark = mark.astype(str)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "1HAJzgLeWk5i",
        "outputId": "a86c93d0-e98b-4850-f298-2c5da1131149"
      },
      "source": [
        "mark.head()\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Roll_No</th>\n",
              "      <th>Name</th>\n",
              "      <th>Marks</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>seema</td>\n",
              "      <td>70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>siddesh</td>\n",
              "      <td>80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>shobha</td>\n",
              "      <td>90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>viswa</td>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>suma</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Roll_No     Name Marks\n",
              "0       1    seema    70\n",
              "1       2  siddesh    80\n",
              "2       3   shobha    90\n",
              "3       4    viswa   100\n",
              "4       5     suma    50"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBF8OYvOWoaQ"
      },
      "source": [
        "list_of_list = [[]]\n",
        "list_of_list[0] = list(mark.columns)\n",
        "list_of_list.extend(mark.values.tolist())"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MhZ1XQ76WtwQ",
        "outputId": "e3476d03-b4fb-4b2c-9967-61fae4f8a931"
      },
      "source": [
        "list_of_list"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['Roll_No', 'Name', 'Marks'],\n",
              " ['1', 'seema', '70'],\n",
              " ['2', 'siddesh', '80'],\n",
              " ['3', 'shobha', '90'],\n",
              " ['4', 'viswa', '100'],\n",
              " ['5', 'suma', '50']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2wPqx3ZWvsM"
      },
      "source": [
        "max_seq_length = 512\n",
        "vocab_file = \"tapas_sqa_base/vocab.txt\"\n",
        "config = tf_example_utils.ClassifierConversionConfig(\n",
        "    vocab_file=vocab_file,\n",
        "    max_seq_length=max_seq_length,\n",
        "    max_column_id=max_seq_length,\n",
        "    max_row_id=max_seq_length,\n",
        "    strip_column_names=False,\n",
        "    add_aggregation_candidates=False,\n",
        ")\n",
        "converter = tf_example_utils.ToClassifierTensorflowExample(config)\n",
        "\n",
        "def convert_interactions_to_examples(tables_and_queries):\n",
        "  \"\"\"Calls Tapas converter to convert interaction to example.\"\"\"\n",
        "  for idx, (table, queries) in enumerate(tables_and_queries):\n",
        "    interaction = interaction_pb2.Interaction()\n",
        "    for position, query in enumerate(queries):\n",
        "      question = interaction.questions.add()\n",
        "      question.original_text = query\n",
        "      question.id = f\"{idx}-0_{position}\"\n",
        "    for header in table[0]:\n",
        "      interaction.table.columns.add().text = header\n",
        "    for line in table[1:]:\n",
        "      row = interaction.table.rows.add()\n",
        "      for cell in line:\n",
        "        row.cells.add().text = cell\n",
        "    number_annotation_utils.add_numeric_values(interaction)\n",
        "    for i in range(len(interaction.questions)):\n",
        "      try:\n",
        "        yield converter.convert(interaction, i)\n",
        "      except ValueError as e:\n",
        "        print(f\"Can't convert interaction: {interaction.id} error: {e}\")\n",
        "        \n",
        "def write_tf_example(filename, examples):\n",
        "  with tf.io.TFRecordWriter(filename) as writer:\n",
        "    for example in examples:\n",
        "      writer.write(example.SerializeToString())\n",
        "\n",
        "def predict(table_data, queries):\n",
        "  table = table_data\n",
        "  examples = convert_interactions_to_examples([(table, queries)])\n",
        "  write_tf_example(\"results/sqa/tf_examples/test.tfrecord\", examples)\n",
        "  write_tf_example(\"results/sqa/tf_examples/random-split-1-dev.tfrecord\", [])\n",
        "  \n",
        "  ! python tapas/tapas/run_task_main.py \\\n",
        "    --task=\"SQA\" \\\n",
        "    --output_dir=\"results\" \\\n",
        "    --noloop_predict \\\n",
        "    --test_batch_size={len(queries)} \\\n",
        "    --tapas_verbosity=\"ERROR\" \\\n",
        "    --compression_type= \\\n",
        "    --init_checkpoint=\"tapas_sqa_base/model.ckpt\" \\\n",
        "    --bert_config_file=\"tapas_sqa_base/bert_config.json\" \\\n",
        "    --mode=\"predict\" 2> error\n",
        "\n",
        "\n",
        "  results_path = \"results/sqa/model/test_sequence.tsv\"\n",
        "  all_coordinates = []\n",
        "  df = pd.DataFrame(table[1:], columns=table[0])\n",
        "  display(IPython.display.HTML(df.to_html(index=False)))\n",
        "  print()\n",
        "  with open(results_path) as csvfile:\n",
        "    reader = csv.DictReader(csvfile, delimiter='\\t')\n",
        "    for row in reader:\n",
        "      coordinates = prediction_utils.parse_coordinates(row[\"answer_coordinates\"])\n",
        "      all_coordinates.append(coordinates)\n",
        "      answers = ', '.join([table[row + 1][col] for row, col in coordinates])\n",
        "      position = int(row['position'])\n",
        "      print(\">\", queries[position])\n",
        "      print(answers)\n",
        "  return all_coordinates"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "id": "RtqNqlD0W11o",
        "outputId": "edb488c2-67cc-4f87-a2de-97631cdf755c"
      },
      "source": [
        "result = predict(list_of_list, [\"what were the names?\",\n",
        "      \"what is the total marks?\",\n",
        "      \"what is the highest marks?\",\n",
        "      \"how many marks has siddesh scored?\",\n",
        "      \"what is the sum of the all marks?\",\"what is the Roll No of viswa?\",\"what is the Average marks of all the students?\"])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "is_built_with_cuda: True\n",
            "is_gpu_available: False\n",
            "GPUs: []\n",
            "Training or predicting ...\n",
            "Evaluation finished after training step 0.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Roll_No</th>\n",
              "      <th>Name</th>\n",
              "      <th>Marks</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>seema</td>\n",
              "      <td>70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>siddesh</td>\n",
              "      <td>80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>shobha</td>\n",
              "      <td>90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>viswa</td>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>suma</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "> what were the names?\n",
            "seema, viswa, shobha, suma, siddesh\n",
            "> what is the total marks?\n",
            "80, 100, 70, 90\n",
            "> what is the highest marks?\n",
            "100\n",
            "> how many marks has siddesh scored?\n",
            "80\n",
            "> what is the sum of the all marks?\n",
            "50\n",
            "> what is the Roll No of viswa?\n",
            "4\n",
            "> what is the Average marks of all the students?\n",
            "100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGr0TChJXI3y"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}